{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib as mpl\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note -- place your own MNIST files in the appropriate directory\n",
    "train_data = np.loadtxt(\"./data/emnist/emnist-balanced-train.csv\", delimiter=',')\n",
    "test_data = np.loadtxt(\"./data/emnist/emnist-balanced-test.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = train_data[:, 1:]  # 10000, 784)\n",
    "test_imgs = test_data[:, 1:]  # (10000, 784)\n",
    "train_labels = train_data[:, 0]  # (10000, )\n",
    "test_labels = test_data[:, 0]  # (10000, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the top k input values to 1, rest of the values to 0\n",
    "def k_cap(input, cap_size):\n",
    "    output = np.zeros_like(input)\n",
    "    if len(input.shape) == 1:\n",
    "        idx = np.argsort(input)[-cap_size:]\n",
    "        output[idx] = 1\n",
    "    else:\n",
    "        idx = np.argsort(input, axis=-1)[:, -cap_size:]\n",
    "        np.put_along_axis(output, idx, 1, axis=-1)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_in = 784\n",
    "n_neurons = 2000\n",
    "cap_size = 200\n",
    "sparsity = 0.1\n",
    "n_rounds = 5\n",
    "beta = 1e0\n",
    "\n",
    "mask = np.zeros((n_neurons, n_neurons), dtype=bool)\n",
    "W = np.zeros((n_neurons, n_neurons))\n",
    "\n",
    "mask_a = np.zeros((n_in, n_neurons), dtype=bool)\n",
    "A = np.zeros((n_in, n_neurons))\n",
    "\n",
    "# Random mask on inter-area connections\n",
    "# Choose 10% of connections and not the diagnal\n",
    "mask = (rng.random((n_neurons, n_neurons)) < sparsity) & np.logical_not(np.eye(n_neurons, dtype=bool))\n",
    "W = np.ones((n_neurons, n_neurons)) * mask\n",
    "W /= W.sum(axis=0)\n",
    "\n",
    "# Random mask on input-learning area connections\n",
    "mask_a = rng.random((n_in, n_neurons)) < sparsity\n",
    "A = np.ones((n_in, n_neurons)) * mask_a\n",
    "A /= A.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve\n",
    "# k-cap on convolved input pixels\n",
    "n_examples = 1000\n",
    "examples = np.zeros((10, n_examples, 784))\n",
    "for i in range(10):\n",
    "    examples[i] = k_cap(convolve(train_imgs[train_labels == i][:n_examples].reshape(-1, 28, 28), np.ones((1, 3, 3)), mode='same').reshape(-1, 28 * 28), cap_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init connections from each neuron to sum up to 1\n",
    "W = np.ones_like(W) * mask\n",
    "A = np.ones_like(A) * mask_a\n",
    "W /= W.sum(axis=0, keepdims=True)\n",
    "A /= A.sum(axis=0, keepdims=True)\n",
    "bias = np.zeros(n_neurons)\n",
    "b = -1\n",
    "activations = np.zeros((10, n_rounds, n_neurons))\n",
    "\n",
    "# Loop over each class\n",
    "for i in range(10):\n",
    "    act_h = np.zeros(n_neurons)\n",
    "    \n",
    "    # Loop over several examples\n",
    "    for j in range(n_rounds):\n",
    "        input = examples[i, j]\n",
    "        \n",
    "        # calculate activation\n",
    "        act_h_new = k_cap(act_h @ W + input @ A + bias, cap_size)\n",
    "        activations[i, j] = act_h_new.copy()\n",
    "        \n",
    "        # update weights\n",
    "        A[(input > 0)[:, np.newaxis] & (act_h_new > 0)[np.newaxis, :]] *= 1 + beta\n",
    "        W[(act_h > 0)[:, np.newaxis] & (act_h_new > 0)[np.newaxis, :]] *= 1 + beta\n",
    "        \n",
    "        act_h = act_h_new\n",
    "        \n",
    "    bias[act_h > 0] += b\n",
    "    A /= A.sum(axis=0, keepdims=True)\n",
    "    W /= W.sum(axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.zeros((10, n_rounds+1, n_examples, n_neurons))\n",
    "for i in np.arange(10):\n",
    "    # Run each example through the model n_round times\n",
    "    for j in range(n_rounds):\n",
    "        outputs[i, j+1] = k_cap(outputs[i, j] @ W + examples[i] @ A, cap_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.full(n_neurons, -1, dtype=int)\n",
    "act = activations[:, -1].copy()       # final state activation after training each class\n",
    "act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, j in enumerate(range(10)):\n",
    "    idx[i*cap_size:(i+1)*cap_size] = act[j].argsort()[-cap_size:][::-1]\n",
    "    act[:, idx[i*cap_size:(i+1)*cap_size]] = -1\n",
    "    \n",
    "r = np.arange(n_neurons)\n",
    "r[idx[idx > -1]] = -1\n",
    "idx[(i+1)*cap_size:] = np.unique(r)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(10, n_rounds, figsize=(10, 2 * 10), sharex=True, sharey=True)\n",
    "for ax, output in zip(axes, outputs):\n",
    "    for i in range(n_rounds):\n",
    "        ax[i].imshow((output[i+1] > 0)[:n_neurons, idx])\n",
    "        ax[i].set_axis_off()\n",
    "fig.text(0.5, 0.04, 'Neurons', ha='center', va='center')\n",
    "fig.text(0.04, 0.5, 'Samples', ha='center', va='center', rotation='vertical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.exp(x).sum(axis=-1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 0.1 * rng.standard_normal((10, n_neurons))\n",
    "targets = np.zeros((100, 10))\n",
    "\n",
    "for i in range(10):\n",
    "    targets[i*10:(i+1)*10, i] = 1\n",
    "update = np.zeros_like(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    permutation = rng.permutation(n_examples - 1000)\n",
    "    for j in range((n_examples - 1000) // 10):\n",
    "        batch = outputs[:, 1, permutation[j*10:(j+1)*10]].reshape(10 * 10, n_neurons)\n",
    "        scores = softmax((batch[:, :, np.newaxis] * v.T[np.newaxis, :, :]).sum(axis=1))\n",
    "        update = 0.5 * update + 1e-3 * (batch[:, np.newaxis, :] * (scores - targets)[:, :, np.newaxis]).sum(axis=0)\n",
    "        v -= update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((outputs[:, 1, :-1000] @ v.T).argmax(axis=-1) == np.arange(10)[:, np.newaxis]).sum() / 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((outputs[:, 1, -1000:] @ v.T).argmax(axis=-1) == np.arange(10)[:, np.newaxis]).sum() / 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "for i in range(10):\n",
    "    # Pass each sample to the model and get its result \n",
    "    ax.bar(np.arange(n_neurons), outputs[i, -1].mean(axis=0)[idx], label=i)\n",
    "ax.legend(loc='upper right', ncol=2)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.set_ylim([0, 1.1])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_xlabel('Neurons')\n",
    "ax.set_ylabel('Firing Probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c is a mask for identifying each assembly\n",
    "# set top k neurons to value 1 and 0 otherwise \n",
    "c = np.zeros((10, n_neurons))\n",
    "use_train_act = True\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    if use_train_act:\n",
    "        # create mask based on the last activation of each class during training\n",
    "        c[i, activations[i, -1].argsort()[-cap_size:]] = 1\n",
    "    else:\n",
    "        # create mask based on the activation after 1 round of ALL the samples for each class\n",
    "        c[i, outputs[i, 1].sum(axis=0).argsort()[-cap_size:]] = 1\n",
    "        \n",
    "predictions = (outputs[:, 1] @ c.T).argmax(axis=-1)\n",
    "acc = (predictions == np.arange(10)[:, np.newaxis]).sum(axis=-1) / n_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 10, figsize=(10, 2))\n",
    "for i in range(10):\n",
    "    axes[i].imshow((A * c[i][np.newaxis, :]).sum(axis=1).reshape(28, 28))\n",
    "    axes[i].set_axis_off()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
